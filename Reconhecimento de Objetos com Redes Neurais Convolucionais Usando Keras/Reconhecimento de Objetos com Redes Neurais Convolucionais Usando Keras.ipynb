{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QQyy6x7LRIfR"
      },
      "cell_type": "markdown",
      "source": [
        "# Reconhecimento de Objetos com Redes Neurais Convolucionais Usando  Keras\n",
        "\n",
        "<b> Jason Brownlee</b>\n",
        "\n",
        "1) É preciso instalar o tensorboard para a visualização\n",
        "\n",
        "$ pip install tensorboard\n",
        "\n",
        "2) Após iniciar a execução abra um terminal no mesmo diretório do jupyter e lance o tensorboard com o seguinte comando:\n",
        "\n",
        "$ tensorboard --logdir=logs/\n",
        "\n",
        "3) O tensorboard irá informa a URL para monitorar a execução:\n",
        "\n",
        "TensorBoard 1.7.0 at http://lccomp-Studio-XPS-8100:6006\n"
      ]
    },
    {
      "metadata": {
        "id": "Vmer5EuByx2C"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Tb6FNL3RIfZ"
      },
      "cell_type": "code",
      "source": [
        "# Plot ad hoc CIFAR10 instances\n",
        "from keras.datasets import cifar10\n",
        "from matplotlib import pyplot\n",
        "from scipy.misc import toimage\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# create a grid of 3x3 images\n",
        "for i in range(0, 9):\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\tpyplot.imshow(toimage(X_train[i]))\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t81Vec5SRIf5"
      },
      "cell_type": "markdown",
      "source": [
        "# Alguns comentários sobre o código\n",
        "\n",
        "\n",
        "<b>Em relação ao padding na convolução</b>\n",
        "\n",
        "    \"VALID\" = sem padding:\n",
        "\n",
        "       inputs:         1  2  3  4  5  6  7  8  9  10 11 (12 13)\n",
        "                      |________________|                dropped\n",
        "                                     |_________________|\n",
        "\n",
        "    \"SAME\" = com zero padding:\n",
        "\n",
        "                   pad|                                      |pad\n",
        "       inputs:      0 |1  2  3  4  5  6  7  8  9  10 11 12 13|0  0\n",
        "                   |________________|\n",
        "                                  |_________________|\n",
        "                                                 |________________|\n",
        "\n",
        "   onde: \n",
        "    entrada = 13\n",
        "    kernel = 6\n",
        "    Stride = 5\n",
        "    \n",
        "\n",
        "<b>Em relação ao kernel_constraint=maxnorm(3)</b>\n",
        "\n",
        "maxnorm (m) irá, se a Norma L2 de seus pesos exceder m, escalar toda a  matriz de peso por um fator que reduza a norma para m. \n",
        "\n",
        "Restringir diretamente a matriz de peso é outro tipo de regularização. Se você usa um termo simples de regularização L2, penaliza os pesos maiores com sua função de perda. Com essa restrição, você regulariza diretamente. Isto parece funcionar especialmente bem em combinação com uma camada de dropout.\n",
        "\n",
        "\n",
        "<b>Em relação ao pooling</b>\n",
        "\n",
        "<i>pool_size</i>: inteiro ou tupla de 2 inteiros indicando fator de redução (vertical, horizontal). (2, 2) irá reduzir pela metade a entrada em ambas as dimensões espaciais. Se apenas um inteiro for especificado, o mesmo tamanho da janela será usado para ambas as dimensões.\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "kruqTtIjRIf-"
      },
      "cell_type": "code",
      "source": [
        "# Simple CNN model for CIFAR-10\n",
        "from time import time\n",
        "import numpy\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Nadam\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#print(\"Xtrain[0] \",X_train[0])\n",
        "#print(\"Ytrain[0] \",y_train[0])\n",
        "\n",
        "\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "#print(\"Xtrain[0] \",X_train[0])\n",
        "#print(\"Ytrain[0] \",y_train[0])\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "epochs =25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "#nadam=Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "#adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32, callbacks=[tensorboard])\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "\n",
        "model.save('modelT1')\n",
        "\n",
        "print(\"\\nFim\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upd5ct9t9jDF"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2eQgyIdtRIgR"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "model = load_model('modelT1')\n",
        "print(model.predict(X_test[:5]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yz5NE0jERIgg"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}